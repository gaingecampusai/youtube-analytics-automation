#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
YouTube ì˜ìƒë³„ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ (ê°œì„  ë²„ì „)
- ë¡±í¼/ìˆí¼ ë¶„ë¦¬ ê¸°ë¡
- ë°°ì¹˜ ì¡°íšŒë¡œ ì†ë„/ì¿¼í„° íš¨ìœ¨ ê°œì„ 
- ì‹œíŠ¸ëŠ” í•œë²ˆì— ì—…ë°ì´íŠ¸
- (ì˜µì…˜) YouTube Analytics í‰ê·  ì‹œì²­ì‹œê°„/ì‹œì²­ë¹„ìœ¨ ì¶”ê°€
"""

import os
import re
import datetime as dt
from datetime import datetime
from typing import List, Dict, Any

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError

from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from google.auth.transport.requests import Request

import gspread

# ========================
# ì„¤ì •
# ========================
YOUTUBE_SCOPES = ['https://www.googleapis.com/auth/youtube.readonly']
SHEETS_SCOPES  = ['https://www.googleapis.com/auth/spreadsheets']
# (ì„ íƒ) YouTube Analytics ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ
USE_YT_ANALYTICS = True
YT_ANALYTICS_SCOPES = ['https://www.googleapis.com/auth/yt-analytics.readonly']

CHANNEL_ID = os.getenv('CHANNEL_ID', 'UCEtPneQeO1IE08MndfjzndQ')
SPREADSHEET_ID = os.getenv('SPREADSHEET_ID', '17Z6bewPmkp00RHpBKymyMaFj4CvqD_QjAPzagmlkCP8')
LONGFORM_SHEET_NAME = 'ìœ íŠœë¸Œ_ì˜ìƒë³„ë¶„ì„(ë¡±í¼)'
SHORTFORM_SHEET_NAME = 'ìœ íŠœë¸Œ_ì˜ìƒë³„ë¶„ì„(ìˆí¼)'

BASE_DIR = os.getenv('BASE_DIR', os.getcwd())
CLIENT_SECRET_FILE = os.getenv('CLIENT_SECRET_FILE', os.path.join(BASE_DIR, 'secrets/client_secret.json'))
TOKEN_YOUTUBE  = os.getenv('TOKEN_YOUTUBE',  os.path.join(BASE_DIR, 'secrets/token_youtube.json'))
TOKEN_SHEETS   = os.getenv('TOKEN_SHEETS',   os.path.join(BASE_DIR, 'secrets/token_sheets.json'))
TOKEN_YTANALYT = os.getenv('TOKEN_YTANALYT', os.path.join(BASE_DIR, 'secrets/token_ytanalytics.json'))

# ========================
# ê³µí†µ: OAuth
# ========================
def load_installed_app_creds(token_path: str, client_secret_path: str, scopes: List[str], local_port: int) -> Credentials:
    creds = None
    if os.path.exists(token_path):
        creds = Credentials.from_authorized_user_file(token_path, scopes)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            flow = InstalledAppFlow.from_client_secrets_file(client_secret_path, scopes)
            # í¬íŠ¸ ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ í¬íŠ¸ ì¸ì ë¶„ë¦¬
            creds = flow.run_local_server(port=local_port)
        with open(token_path, 'w') as f:
            f.write(creds.to_json())
    return creds

def get_youtube_client() -> Any:
    yt_creds = load_installed_app_creds(TOKEN_YOUTUBE, CLIENT_SECRET_FILE, YOUTUBE_SCOPES, local_port=8081)
    return build('youtube', 'v3', credentials=yt_creds), yt_creds

def get_sheets_client() -> gspread.Client:
    sheets_creds = load_installed_app_creds(TOKEN_SHEETS, CLIENT_SECRET_FILE, SHEETS_SCOPES, local_port=8082)
    return gspread.authorize(sheets_creds)

def get_yt_analytics_client() -> Any:
    # YouTube AnalyticsëŠ” YouTubeì™€ ê°™ì€ í† í° ì‚¬ìš© (yt_monthly_report_test.py ì°¸ê³ )
    yt_analyt_creds = load_installed_app_creds(TOKEN_YOUTUBE, CLIENT_SECRET_FILE, YOUTUBE_SCOPES + YT_ANALYTICS_SCOPES, local_port=8081)
    return build('youtubeAnalytics', 'v2', credentials=yt_analyt_creds)

# ========================
# YouTube ë°ì´í„° ìˆ˜ì§‘
# ========================
DUR_RE_H = re.compile(r'(\d+)H')
DUR_RE_M = re.compile(r'(\d+)M')
DUR_RE_S = re.compile(r'(\d+)S')

def parse_duration_to_seconds(iso_dur: str) -> int:
    """ISO 8601 duration (e.g., PT2H37M15S) â†’ seconds"""
    if not iso_dur or not iso_dur.startswith('PT'):
        return 0
    total = 0
    h = DUR_RE_H.search(iso_dur)
    m = DUR_RE_M.search(iso_dur)
    s = DUR_RE_S.search(iso_dur)
    if h: total += int(h.group(1)) * 3600
    if m: total += int(m.group(1)) * 60
    if s: total += int(s.group(1))
    return total

def fetch_uploads_playlist_id(youtube, channel_id: str) -> str:
    resp = youtube.channels().list(part='contentDetails', id=channel_id).execute()
    items = resp.get('items', [])
    if not items:
        raise ValueError(f'ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {channel_id}')
    return items[0]['contentDetails']['relatedPlaylists']['uploads']

def fetch_all_playlist_video_ids(youtube, playlist_id: str, max_videos: int = 50) -> List[str]:
    """ì—…ë¡œë“œ ì¬ìƒëª©ë¡ì—ì„œ ìµœì‹  ì˜ìƒ IDë“¤ì„ ê°€ì ¸ì˜¤ê¸° (ìµœëŒ€ max_videosê°œ)"""
    ids = []
    req = youtube.playlistItems().list(
        part='contentDetails',
        playlistId=playlist_id,
        maxResults=50
    )
    while req and len(ids) < max_videos:
        resp = req.execute()
        for it in resp.get('items', []):
            if len(ids) >= max_videos:
                break
            vid = it['contentDetails']['videoId']
            ids.append(vid)
        req = youtube.playlistItems().list_next(req, resp)
    return ids

def chunked(iterable: List[str], size: int):
    for i in range(0, len(iterable), size):
        yield iterable[i:i+size]

def fetch_videos_meta(youtube, video_ids: List[str]) -> List[Dict[str, Any]]:
    """videos().listë¥¼ ë°°ì¹˜ë¡œ í˜¸ì¶œí•˜ì—¬ ë©”íƒ€/í†µê³„ë¥¼ ìˆ˜ì§‘"""
    out = []
    for batch in chunked(video_ids, 50):
        resp = youtube.videos().list(
            part='snippet,statistics,contentDetails',
            id=','.join(batch),
            maxResults=50
        ).execute()
        for v in resp.get('items', []):
            sn = v.get('snippet', {})
            st = v.get('statistics', {})
            cd = v.get('contentDetails', {})
            dur = cd.get('duration', 'PT0S')
            sec = parse_duration_to_seconds(dur)
            is_short = sec <= 60  # Shorts íœ´ë¦¬ìŠ¤í‹±

            out.append({
                'id': v.get('id'),
                'title': sn.get('title', ''),
                'upload_date': (sn.get('publishedAt', '')[:10] or ''),
                'views': int(st.get('viewCount', 0) or 0),
                'likes': int(st.get('likeCount', 0) or 0),
                'comments': int(st.get('commentCount', 0) or 0),
                'duration': dur,
                'duration_seconds': sec,
                'is_short': is_short,
                'url': f"https://www.youtube.com/watch?v={v.get('id')}"
            })
    return out

# ========================
# (ì„ íƒ) YouTube Analytics
# ========================
def fetch_yt_analytics_for_videos(yt_analytics, video_ids: List[str]) -> Dict[str, Dict[str, float]]:
    """
    ê° ë¹„ë””ì˜¤ë³„ë¡œ í‰ê·  ì‹œì²­ì‹œê°„(ì´ˆ), í‰ê·  ì‹œì²­ ë¹„ìœ¨(%)ì„ ì¡°íšŒ
    - yt_monthly_report_test.py ìŠ¤íƒ€ì¼ë¡œ êµ¬í˜„
    """
    results = {}
    
    # ë°°ì¹˜ë¡œ ì²˜ë¦¬ (50ê°œì”©)
    for batch in chunked(video_ids, 50):
        try:
            # ìµœê·¼ 30ì¼ ë°ì´í„°ë¡œ ì¡°íšŒ (ë” ì•ˆì •ì )
            end_date = datetime.utcnow().date()
            start_date = end_date - dt.timedelta(days=30)
            
            resp = yt_analytics.reports().query(
                ids=f'channel=={CHANNEL_ID}',
                startDate=start_date.isoformat(),
                endDate=end_date.isoformat(),
                metrics='averageViewDuration,averageViewPercentage',
                dimensions='video',
                filters=f'video=={",".join(batch)}'
            ).execute()
            
            rows = resp.get('rows', [])
            for row in rows:
                vid, avg_dur, avg_pct = row
                results[vid] = {
                    'avg_view_duration': float(avg_dur or 0.0),
                    'avg_view_percentage': float(avg_pct or 0.0),
                }
            
            # ë°ì´í„°ê°€ ì—†ëŠ” ë¹„ë””ì˜¤ëŠ” 0ìœ¼ë¡œ ì„¤ì •
            for vid in batch:
                if vid not in results:
                    results[vid] = {'avg_view_duration': 0.0, 'avg_view_percentage': 0.0}
                    
        except HttpError as e:
            print(f"Analytics API ì˜¤ë¥˜ (ë°°ì¹˜): {e}")
            # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” ëª¨ë‘ 0ìœ¼ë¡œ ì„¤ì •
            for vid in batch:
                results[vid] = {'avg_view_duration': 0.0, 'avg_view_percentage': 0.0}
    
    return results

# ========================
# Sheets ê¸°ë¡
# ========================
LONG_HEADERS = [
    'No', 'videoId', 'ì˜ìƒ ì œëª©', 'ì—…ë¡œë“œì¼', 'ì¡°íšŒìˆ˜', 'ì¢‹ì•„ìš”', 'ëŒ“ê¸€',
    'ì‹œì²­ ìœ ì§€ìœ¨(%)', 'í‰ê·  ì‹œì²­ì‹œê°„(ì´ˆ)', 'ê¸¸ì´(ì´ˆ)', 'Shorts ì—¬ë¶€', 'ì˜ìƒ ë§í¬', 'ë¹„ê³ '
]

def build_sheet_rows(videos: List[Dict[str, Any]], analytics: Dict[str, Dict[str, float]] = None) -> List[List[Any]]:
    rows = []
    for i, v in enumerate(videos, 1):
        vid = v['id']
        avg_pct = ''
        avg_dur = ''
        if analytics is not None and vid in analytics:
            avg_pct = round(analytics[vid].get('avg_view_percentage', 0.0), 2)
            avg_dur = round(analytics[vid].get('avg_view_duration', 0.0), 2)
        rows.append([
            i,
            vid,
            v['title'],
            v['upload_date'],
            v['views'],
            v['likes'],
            v['comments'],
            avg_pct,            # ì‹œì²­ ìœ ì§€ìœ¨(%)
            avg_dur,            # í‰ê·  ì‹œì²­ì‹œê°„(ì´ˆ)
            v['duration_seconds'],
            'Y' if v['is_short'] else 'N',
            v['url'],
            ''                  # ë¹„ê³ 
        ])
    return rows

def write_sheet(gc: gspread.Client, sheet_name: str, headers: List[str], rows: List[List[Any]]):
    sh = gc.open_by_key(SPREADSHEET_ID)
    try:
        ws = sh.worksheet(sheet_name)
    except gspread.WorksheetNotFound:
        ws = sh.add_worksheet(title=sheet_name, rows=1000, cols=len(headers))

    # ì „ì²´ ì§€ìš°ê³  í—¤ë”+ë°ì´í„° í•œë²ˆì— ì—…ë°ì´íŠ¸ (ë¹ ë¦„)
    ws.clear()
    values = [headers] + rows
    ws.update('A1', values, value_input_option='RAW')

# ========================
# ë©”ì¸
# ========================
def main():
    print("ğŸ¬ YouTube ì˜ìƒë³„ ë¶„ì„ ì‹œì‘")
    print(f"ğŸ“Š ì±„ë„ ID: {CHANNEL_ID}")
    print(f"ğŸ“ ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID: {SPREADSHEET_ID}")

    try:
        # í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„
        print("ğŸ” YouTube ì¸ì¦ ì¤‘...")
        youtube, yt_creds = get_youtube_client()

        print("ğŸ“¹ ì—…ë¡œë“œ ì¬ìƒëª©ë¡ ì¡°íšŒ...")
        uploads_pid = fetch_uploads_playlist_id(youtube, CHANNEL_ID)

        print("ğŸ“¹ ì˜ìƒ ID ìˆ˜ì§‘ ì¤‘... (ìµœì‹  100ê°œ)")
        video_ids = fetch_all_playlist_video_ids(youtube, uploads_pid, max_videos=100)
        if not video_ids:
            print("âŒ ì—…ë¡œë“œëœ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        print(f"âœ… ì´ {len(video_ids)}ê°œ ì˜ìƒ ID ìˆ˜ì§‘")

        print("ğŸ“¦ ë©”íƒ€/í†µê³„ ë°°ì¹˜ ì¡°íšŒ ì¤‘...")
        videos = fetch_videos_meta(youtube, video_ids)

        # ë¡±í¼/ìˆí¼ ë¶„ë¦¬ í›„ TOP 20ê°œì”©ë§Œ ì„ íƒ
        long_videos  = [v for v in videos if not v['is_short']]
        short_videos = [v for v in videos if v['is_short']]
        
        # ì¡°íšŒìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ TOP 20ê°œ ì„ íƒ
        long_videos.sort(key=lambda x: x['views'], reverse=True)
        short_videos.sort(key=lambda x: x['views'], reverse=True)
        
        long_videos = long_videos[:20]
        short_videos = short_videos[:20]
        
        print(f"ğŸ“ ë¡±í¼ TOP {len(long_videos)}ê°œ, ìˆí¼ TOP {len(short_videos)}ê°œ")

        # (ì„ íƒ) YouTube Analytics
        analytics_map = None
        if USE_YT_ANALYTICS:
            print("ğŸ“ˆ YouTube Analytics ì¸ì¦/ì¡°íšŒ ì¤‘...")
            yt_analytics = get_yt_analytics_client()
            # TOP 20ê°œ ì˜ìƒë§Œ Analytics ì¡°íšŒ
            top_video_ids = [v['id'] for v in long_videos + short_videos]
            analytics_map = fetch_yt_analytics_for_videos(yt_analytics, top_video_ids)

        # ì‹œíŠ¸ ê¸°ë¡
        print("ğŸ“Š Google Sheets ì¸ì¦ ì¤‘...")
        gc = get_sheets_client()

        print("ğŸ“ ì‹œíŠ¸ì— ì“°ëŠ” ì¤‘ (ì¼ê´„ ì—…ë°ì´íŠ¸)...")
        long_rows  = build_sheet_rows(long_videos, analytics_map)
        short_rows = build_sheet_rows(short_videos, analytics_map)

        write_sheet(gc, LONGFORM_SHEET_NAME,  LONG_HEADERS, long_rows)
        write_sheet(gc, SHORTFORM_SHEET_NAME, LONG_HEADERS, short_rows)

        print("ğŸ‰ ì˜ìƒë³„ ë¶„ì„ ì™„ë£Œ!")

    except HttpError as e:
        print(f"âŒ YouTube API ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"âŒ ì¼ë°˜ ì˜¤ë¥˜: {e}")

if __name__ == '__main__':
    main()